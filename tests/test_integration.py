#!/usr/bin/env python3
"""
Integration tests for Lab Manager

These tests verify the complete workflow including:
- Docker image building
- Container creation and management
- Network isolation
- Port mapping
- CSV integration
- Cleanup operations

These tests require Docker to be available and will create actual containers.
Run with: pytest tests/test_integration.py -v -s
"""

import pytest
import tempfile
import os
import csv
import time
import subprocess
import json
from typing import List, Dict
import sys

# Import the classes we want to test
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from lab_manager import LabManager, StudentData
from tests.conftest import create_csv_with_data


class TestDockerIntegration:
    """Integration tests that require Docker"""
    
    def _needs_sudo_for_docker(self) -> bool:
        """Check if Docker requires sudo by trying a simple command"""
        try:
            result = subprocess.run(
                ["docker", "info"], 
                capture_output=True, 
                text=True, 
                timeout=10
            )
            return result.returncode != 0
        except:
            # If Docker command fails, assume we need sudo
            return True
    
    @pytest.fixture(autouse=True)
    def setup_and_teardown(self):
        """Setup and teardown for each test"""
        # Auto-detect if sudo is needed for Docker
        use_sudo = self._needs_sudo_for_docker()
        print(f"\nðŸ”§ Using sudo for Docker: {use_sudo}")
        
        self.lab_manager = LabManager(use_sudo=use_sudo)
        self.test_csv_files = []
        self.created_networks = []
        self.created_containers = []
        
        yield
        
        # Cleanup after each test
        self.cleanup_test_resources()
    
    def cleanup_test_resources(self):
        """Clean up any Docker resources created during tests"""
        print("\nðŸ§¹ Cleaning up test resources...")
        
        # First: Stop and remove any test containers
        try:
            result = self.lab_manager.run_command(["docker", "ps", "-a", "--format", "{{.Names}}"])
            container_names = result.stdout.strip().split('\n') if result.stdout.strip() else []
            
            for name in container_names:
                if name and ('test' in name and ('kali-jump' in name or 'ubuntu-target' in name)):
                    print(f"  Removing container {name}")
                    try:
                        self.lab_manager.run_command(["docker", "rm", "-f", name])
                    except Exception as e:
                        print(f"    âš ï¸  Failed to remove container {name}: {e}")
        except Exception as e:
            print(f"  âš ï¸  Error listing containers: {e}")
        
        # Second: Remove any test networks (containers should be gone now)
        try:
            result = self.lab_manager.run_command(["docker", "network", "ls", "--format", "{{.Name}}"])
            network_names = result.stdout.strip().split('\n') if result.stdout.strip() else []
            
            for name in network_names:
                if name and ('cyber-lab-test' in name or 'cyber-lab-student' in name or 'cyber-lab-nettest' in name):
                    print(f"  Removing network {name}")
                    try:
                        self.lab_manager.run_command(["docker", "network", "rm", name])
                    except Exception as e:
                        print(f"    âš ï¸  Failed to remove network {name}: {e}")
        except Exception as e:
            print(f"  âš ï¸  Error listing networks: {e}")
        
        # Third: Also try to remove by project name (this should clean up compose projects)
        project_names = [
            'teststudent001', 'teststudent002', 'teststudent003', 
            'testparallel001', 'testparallel002', 'testparallel003', 
            'nettest001', 'nettest002',
            'individualtest001', 'removetest001', 'recreatetest001',
            'reconciletest001', 'reconciletest002', 'extratest001', 'extratest002', 'extratest003',
            'assigntest001', 'assigntest002', 'mixedtest001', 'mixedtest002', 'mixedtest003',
            'exectest001', 'maptest001', 'functest001'  # Add our new exec test projects
        ]
        for project in project_names:
            try:
                print(f"  Cleaning up docker-compose project: cyber-lab-{project}")
                self.lab_manager.run_command([
                    "docker", "compose", "-p", f"cyber-lab-{project}", "down", "-v", "--remove-orphans"
                ])
            except Exception as e:
                print(f"    âš ï¸  Failed to clean up project cyber-lab-{project}: {e}")
        
        # Clean up CSV files
        for csv_file in self.test_csv_files:
            try:
                os.unlink(csv_file)
            except Exception as e:
                print(f"  âš ï¸  Failed to remove CSV file {csv_file}: {e}")
    
    def create_test_csv(self, students_data: List[dict]) -> str:
        """Helper to create a temporary CSV file with test data"""
        temp_file = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv')
        create_csv_with_data(temp_file.name, students_data)
        self.test_csv_files.append(temp_file.name)
        return temp_file.name
    
    def wait_for_container_ready(self, container_name: str, max_wait: int = 30) -> bool:
        """Wait for a container to be ready"""
        print(f"    â³ Waiting for container {container_name}...")
        for i in range(max_wait):
            try:
                # Check if container exists and is running
                result = self.lab_manager.run_command([
                    "docker", "ps", "--filter", f"name={container_name}", 
                    "--filter", "status=running", "--format", "{{.Names}}"
                ])
                if container_name in result.stdout:
                    print(f"    âœ… Container {container_name} is ready")
                    return True
                    
                # Also try without status filter in case container is still starting
                result = self.lab_manager.run_command([
                    "docker", "ps", "-a", "--filter", f"name={container_name}", 
                    "--format", "{{.Names}}"
                ])
                if container_name in result.stdout:
                    # Container exists but may not be running yet
                    print(f"    ðŸ“¦ Container {container_name} exists, waiting for ready state... ({i+1}/{max_wait})")
                else:
                    print(f"    â“ Container {container_name} not found yet... ({i+1}/{max_wait})")
                    
                time.sleep(1)
            except Exception as e:
                print(f"    âš ï¸  Error checking container {container_name}: {e}")
                time.sleep(1)
        
        print(f"    âŒ Container {container_name} failed to become ready within {max_wait} seconds")
        return False
    
    def check_container_health(self, container_name: str) -> Dict:
        """Check the health/status of a container"""
        try:
            result = self.lab_manager.run_command([
                "docker", "inspect", container_name, "--format", "{{json .State}}"
            ])
            state = json.loads(result.stdout.strip())
            return {
                'status': state.get('Status', 'unknown'),
                'running': state.get('Running', False),
                'exit_code': state.get('ExitCode', -1)
            }
        except Exception as e:
            print(f"    âš ï¸  Error inspecting container {container_name}: {e}")
            return {'status': 'not_found', 'running': False, 'exit_code': -1}
    
    def check_port_accessibility(self, port: int) -> bool:
        """Check if a port is accessible (bound)"""
        try:
            result = subprocess.run([
                "ss", "-tuln", f"sport = :{port}"
            ], capture_output=True, text=True, timeout=5)
            return str(port) in result.stdout
        except:
            return False


@pytest.mark.integration
class TestFullWorkflow(TestDockerIntegration):
    """Test the complete lab management workflow"""
    
    def test_build_images(self):
        """Test building Docker images"""
        print("\nðŸ”¨ Testing image build...")
        
        # Check if docker-compose.yml exists
        compose_file = "docker-compose.yml"
        assert os.path.exists(compose_file), "docker-compose.yml not found"
        
        # Build images
        success = self.lab_manager.build_images()
        assert success, "Docker image build failed"
        
        # Verify images were created
        result = self.lab_manager.run_command(["docker", "images", "--format", "json"])
        images = []
        if result.stdout.strip():
            for line in result.stdout.strip().split('\n'):
                if line:
                    images.append(json.loads(line))
        
        # Look for our expected images
        image_names = [img.get('Repository', '') for img in images]
        expected_images = ['epic-research-infra-kali-jump', 'epic-research-infra-ubuntu-target1']

        found_images = []
        for expected in expected_images:
            for image_name in image_names:
                if expected in image_name:
                    found_images.append(expected)
                    break
        
        print(f"Found images: {found_images}")
        assert len(found_images) >= 2, f"Expected to find 2 images, found: {found_images}"
    
    @pytest.mark.slow
    def test_single_student_lifecycle(self):
        """Test complete lifecycle for a single student"""
        print("\nðŸ‘¤ Testing single student lifecycle...")
        
        # Create test CSV with one student
        test_data = [
            {'student_id': 'teststudent001', 'student_name': 'Test Student', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Step 1: Spin up student
        print("  ðŸ“¤ Spinning up student containers...")
        success = self.lab_manager.spin_up_single_student('teststudent001', csv_file)
        assert success, "Failed to spin up student containers"
        
        # Step 2: Wait for containers to be ready
        print("  â³ Waiting for containers to be ready...")
        container_ready = self.wait_for_container_ready('kali-jump-teststudent001', max_wait=60)
        assert container_ready, "Kali container failed to start within timeout"
        
        # Step 3: Check container health
        print("  ðŸ” Checking container health...")
        kali_health = self.check_container_health('kali-jump-teststudent001')
        assert kali_health['running'], f"Kali container not running: {kali_health}"
        
        # Step 4: Verify network isolation
        print("  ðŸŒ Verifying network isolation...")
        result = self.lab_manager.run_command(["docker", "network", "ls", "--format", "json"])
        networks = []
        if result.stdout.strip():
            for line in result.stdout.strip().split('\n'):
                if line:
                    networks.append(json.loads(line))
        
        student_networks = [net for net in networks if 'cyber-lab-teststudent001' in net.get('Name', '')]
        assert len(student_networks) >= 1, "Student network not found"
        
        # Step 5: Check port mapping
        print("  ðŸ”Œ Checking port mapping...")
        students = self.lab_manager.read_students_csv(csv_file)
        student = students[0]
        assert student['port'] >= 2222, f"Invalid port assignment: {student['port']}"
        
        # Check if port is actually bound
        port_bound = self.check_port_accessibility(student['port'])
        # Note: This might fail in some environments, so we'll just log it
        print(f"  Port {student['port']} bound: {port_bound}")
        
        # Step 6: Test container interaction
        print("  ðŸ’¬ Testing container interaction...")
        try:
            # Try to execute a simple command in the kali container
            result = self.lab_manager.run_command([
                "docker", "exec", "kali-jump-teststudent001", 
                "echo", "test-connection-success"
            ])
            assert "test-connection-success" in result.stdout, "Container command execution failed"
        except Exception as e:
            pytest.fail(f"Container interaction test failed: {e}")
        
        # Step 7: Test cleanup
        print("  ðŸ—‘ï¸  Testing cleanup...")
        success = self.lab_manager.spin_down_student('teststudent001', csv_file)
        assert success, "Failed to spin down student containers"
        
        # Verify containers are gone
        time.sleep(3)  # Give Docker time to clean up
        kali_health_after = self.check_container_health('kali-jump-teststudent001')
        assert not kali_health_after['running'], "Container still running after cleanup"
    
    @pytest.mark.slow  
    def test_multi_student_class_sequential(self):
        """Test managing a small class of students in sequential mode"""
        print("\nðŸ« Testing multi-student class management (sequential)...")
        
        # Create test CSV with multiple students
        test_data = [
            {'student_id': 'teststudent001', 'student_name': 'Alice Test', 'port': '', 'subnet_id': ''},
            {'student_id': 'teststudent002', 'student_name': 'Bob Test', 'port': '', 'subnet_id': ''},
            {'student_id': 'teststudent003', 'student_name': 'Carol Test', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Step 1: Spin up entire class (sequential to avoid resource conflicts)
        print("  ðŸ“¤ Spinning up class (sequential mode)...")
        success = self.lab_manager.spin_up_class(csv_file, parallel=False)
        assert success, "Failed to spin up class"
        
        # Step 2: Verify all students have containers
        print("  ðŸ” Verifying all student containers...")
        students = self.lab_manager.read_students_csv(csv_file)
        assert len(students) == 3, f"Expected 3 students, found {len(students)}"
        
        # Check that all students have unique ports and subnets
        ports = [s['port'] for s in students]
        subnets = [s['subnet_id'] for s in students]
        assert len(set(ports)) == 3, f"Duplicate ports found: {ports}"
        assert len(set(subnets)) == 3, f"Duplicate subnets found: {subnets}"
        
        # Step 3: Check container status for each student
        running_containers = 0
        for student in students:
            container_name = f"kali-jump-{student['student_id']}"
            if self.wait_for_container_ready(container_name, max_wait=30):
                health = self.check_container_health(container_name)
                if health['running']:
                    running_containers += 1
                    print(f"  âœ… {student['student_id']} container running")
                else:
                    print(f"  âŒ {student['student_id']} container not running: {health}")
        
        assert running_containers >= 2, f"Only {running_containers}/3 containers running"
        
        # Step 4: Test reconciliation
        print("  ðŸ”„ Testing reconciliation...")
        success = self.lab_manager.reconcile_with_csv(csv_file)
        assert success, "Reconciliation failed"
        
        # Step 5: Clean up entire class
        print("  ðŸ—‘ï¸  Cleaning up entire class...")
        success = self.lab_manager.spin_down_class(csv_file, parallel=False)
        assert success, "Failed to spin down class"
        
        # Verify cleanup
        time.sleep(5)  # Give Docker time to clean up
        running_after_cleanup = 0
        for student in students:
            container_name = f"kali-jump-{student['student_id']}"
            health = self.check_container_health(container_name)
            if health['running']:
                running_after_cleanup += 1
        
        assert running_after_cleanup == 0, f"Still {running_after_cleanup} containers running after cleanup"
    
    @pytest.mark.slow
    def test_multi_student_class_parallel(self):
        """Test managing a small class of students in parallel mode"""
        print("\nðŸ« Testing multi-student class management (parallel)...")
        
        # Create test CSV with multiple students
        test_data = [
            {'student_id': 'testparallel001', 'student_name': 'Alice Parallel', 'port': '', 'subnet_id': ''},
            {'student_id': 'testparallel002', 'student_name': 'Bob Parallel', 'port': '', 'subnet_id': ''},
            {'student_id': 'testparallel003', 'student_name': 'Carol Parallel', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Step 1: Test parallel spin up (with mock user confirmation)
        print("  ðŸ“¤ Spinning up class (parallel mode)...")
        # Override the confirmation method to automatically accept parallel execution
        original_confirm = self.lab_manager._confirm_parallel_execution
        self.lab_manager._confirm_parallel_execution = lambda operation_name: True
        
        try:
            success = self.lab_manager.spin_up_class(csv_file, parallel=True)
            assert success, "Failed to spin up class in parallel"
            
            # Step 2: Verify all students have containers and unique assignments
            print("  ðŸ” Verifying all student containers...")
            students = self.lab_manager.read_students_csv(csv_file)
            assert len(students) == 3, f"Expected 3 students, found {len(students)}"
            
            # Check that all students have unique ports and subnets (critical for parallel execution)
            ports = [s['port'] for s in students]
            subnets = [s['subnet_id'] for s in students]
            assert len(set(ports)) == 3, f"Duplicate ports found in parallel execution: {ports}"
            assert len(set(subnets)) == 3, f"Duplicate subnets found in parallel execution: {subnets}"
            
            # Step 3: Wait for containers to be ready (parallel execution may take longer)
            print("  â³ Waiting for all containers to be ready...")
            running_containers = 0
            for student in students:
                container_name = f"kali-jump-{student['student_id']}"
                # Give more time for parallel execution
                if self.wait_for_container_ready(container_name, max_wait=45):
                    health = self.check_container_health(container_name)
                    if health['running']:
                        running_containers += 1
                        print(f"  âœ… {student['student_id']} container running")
                    else:
                        print(f"  âŒ {student['student_id']} container not running: {health}")
            
            # In parallel mode, we should expect all containers to start
            assert running_containers >= 2, f"Only {running_containers}/3 containers running in parallel mode"
            
            # Step 4: Test parallel reconciliation
            print("  ðŸ”„ Testing reconciliation...")
            success = self.lab_manager.reconcile_with_csv(csv_file)
            assert success, "Reconciliation failed"
            
            # Step 5: Test parallel cleanup
            print("  ðŸ—‘ï¸  Cleaning up entire class (parallel mode)...")
            success = self.lab_manager.spin_down_class(csv_file, parallel=True)
            assert success, "Failed to spin down class in parallel"
            
            # Verify cleanup (give more time for parallel cleanup)
            time.sleep(8)  # Give Docker more time for parallel cleanup
            running_after_cleanup = 0
            for student in students:
                container_name = f"kali-jump-{student['student_id']}"
                health = self.check_container_health(container_name)
                if health['running']:
                    running_after_cleanup += 1
            
            assert running_after_cleanup == 0, f"Still {running_after_cleanup} containers running after parallel cleanup"
            
        finally:
            # Restore original confirmation method
            self.lab_manager._confirm_parallel_execution = original_confirm
    
    def test_error_handling(self):
        """Test error handling scenarios"""
        print("\nðŸš¨ Testing error handling...")
        
        # Test 1: Try to spin up non-existent student
        print("  Testing non-existent student...")
        success = self.lab_manager.spin_down_student('nonexistent')
        assert not success, "Should fail when trying to manage non-existent student"
        
        # Test 2: Try with invalid CSV
        print("  Testing invalid CSV...")
        invalid_csv = "/tmp/nonexistent.csv"
        students = self.lab_manager.read_students_csv(invalid_csv)
        assert students == [], "Should return empty list for non-existent CSV"
        
        # Test 3: Try to spin up with missing CSV
        print("  Testing missing CSV file...")
        success = self.lab_manager.spin_up_class("/tmp/nonexistent.csv")
        assert not success, "Should fail with non-existent CSV"


@pytest.mark.integration  
class TestIndividualStudentOperations(TestDockerIntegration):
    """Test individual student management operations"""
    
    @pytest.mark.slow
    def test_add_single_student(self):
        """Test adding a single student"""
        print("\nðŸ‘¤ Testing add single student...")
        
        # Create test CSV with one student (no assignments yet)
        test_data = [
            {'student_id': 'individualtest001', 'student_name': 'Individual Test Student', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Add the student
        success = self.lab_manager.spin_up_single_student('individualtest001', csv_file)
        assert success, "Failed to add single student"
        
        # Verify container is running
        container_ready = self.wait_for_container_ready('kali-jump-individualtest001', max_wait=30)
        assert container_ready, "Container failed to start"
        
        health = self.check_container_health('kali-jump-individualtest001')
        assert health['running'], f"Container not running: {health}"
        
        # Verify CSV was updated with assignments
        students = self.lab_manager.read_students_csv(csv_file)
        student = students[0]
        assert student['port'] >= 2222, f"Port not assigned: {student['port']}"
        assert student['subnet_id'] is not None and int(student['subnet_id']) > 0, f"Subnet not assigned: {student['subnet_id']}"
        
        # Cleanup
        success = self.lab_manager.spin_down_student('individualtest001', csv_file)
        assert success, "Failed to remove student"
    
    @pytest.mark.slow
    def test_remove_single_student(self):
        """Test removing a single student"""
        print("\nðŸ‘¤ Testing remove single student...")
        
        # Create and start a student first
        test_data = [
            {'student_id': 'removetest001', 'student_name': 'Remove Test Student', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Add student
        success = self.lab_manager.spin_up_single_student('removetest001', csv_file)
        assert success, "Failed to add student for removal test"
        
        # Wait for container
        container_ready = self.wait_for_container_ready('kali-jump-removetest001', max_wait=30)
        assert container_ready, "Container failed to start"
        
        # Now test removal
        success = self.lab_manager.spin_down_student('removetest001', csv_file)
        assert success, "Failed to remove student"
        
        # Verify container is gone
        time.sleep(3)
        health = self.check_container_health('kali-jump-removetest001')
        assert not health['running'], "Container still running after removal"
    
    @pytest.mark.slow
    def test_recreate_student(self):
        """Test recreating a student's containers"""
        print("\nðŸ”„ Testing recreate student...")
        
        # Create and start a student first
        test_data = [
            {'student_id': 'recreatetest001', 'student_name': 'Recreate Test Student', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Add student initially
        success = self.lab_manager.spin_up_single_student('recreatetest001', csv_file)
        assert success, "Failed to add student for recreate test"
        
        container_ready = self.wait_for_container_ready('kali-jump-recreatetest001', max_wait=30)
        assert container_ready, "Initial container failed to start"
        
        # Recreate the student
        success = self.lab_manager.recreate_student('recreatetest001', csv_file)
        assert success, "Failed to recreate student"
        
        # Wait for new container to be ready
        container_ready = self.wait_for_container_ready('kali-jump-recreatetest001', max_wait=30)
        assert container_ready, "Recreated container failed to start"
        
        # Verify container is running (this ensures recreation was successful)
        health = self.check_container_health('kali-jump-recreatetest001')
        assert health['running'], f"Container not running after recreation: {health}"
        
        # Cleanup
        self.lab_manager.spin_down_student('recreatetest001', csv_file)
        
        # Cleanup
        self.lab_manager.spin_down_student('recreatetest001', csv_file)


@pytest.mark.integration
class TestReconciliation(TestDockerIntegration):
    """Test reconciliation functionality"""
    
    @pytest.mark.slow
    def test_reconcile_missing_students(self):
        """Test reconciliation when students are missing from running environment"""
        print("\nðŸ”„ Testing reconcile with missing students...")
        
        # Create CSV with students but DON'T start them - test the ADD case
        test_data = [
            {'student_id': 'reconciletest001', 'student_name': 'Reconcile Test 1', 'port': '', 'subnet_id': ''},
            {'student_id': 'reconciletest002', 'student_name': 'Reconcile Test 2', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Verify no containers are running initially
        health1_before = self.check_container_health('kali-jump-reconciletest001')
        health2_before = self.check_container_health('kali-jump-reconciletest002')
        assert not health1_before['running'], "Container 1 should not be running initially"
        assert not health2_before['running'], "Container 2 should not be running initially"
        
        # Run reconciliation (should ADD the missing students)
        success = self.lab_manager.reconcile_with_csv(csv_file)
        assert success, "Reconciliation failed"
        
        # Verify students were ADDED by reconciliation
        container1_ready = self.wait_for_container_ready('kali-jump-reconciletest001', max_wait=30)
        container2_ready = self.wait_for_container_ready('kali-jump-reconciletest002', max_wait=30)
        
        assert container1_ready, "First student container not started by reconciliation"
        assert container2_ready, "Second student container not started by reconciliation"
        
        # Verify containers are actually running
        health1 = self.check_container_health('kali-jump-reconciletest001')
        health2 = self.check_container_health('kali-jump-reconciletest002')
        
        assert health1['running'], "First student not running after reconciliation"
        assert health2['running'], "Second student not running after reconciliation"
        
        # Verify assignments were made during reconciliation
        students = self.lab_manager.read_students_csv(csv_file)
        assert len(students) == 2, "Should have 2 students"
        for student in students:
            assert student['port'] >= 2222, f"Port not assigned during reconciliation: {student}"
            assert student['subnet_id'] is not None and int(student['subnet_id']) > 0, f"Subnet not assigned during reconciliation: {student}"
        
        print(f"  âœ… Reconciliation successfully ADDED {len(students)} missing students")
        
        # Cleanup
        self.lab_manager.spin_down_class(csv_file, parallel=False)
    
    @pytest.mark.slow
    def test_reconcile_extra_containers(self):
        """Test reconciliation when there are extra running containers that need to be REMOVED"""
        print("\nðŸ”„ Testing reconcile with extra containers (REMOVE case)...")
        
        # Step 1: Start with 3 students
        initial_data = [
            {'student_id': 'extratest001', 'student_name': 'Extra Test 1', 'port': '', 'subnet_id': ''},
            {'student_id': 'extratest002', 'student_name': 'Extra Test 2', 'port': '', 'subnet_id': ''},
            {'student_id': 'extratest003', 'student_name': 'Extra Test 3', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(initial_data)
        
        # Start all 3 students
        success = self.lab_manager.spin_up_class(csv_file, parallel=False)
        assert success, "Failed to start initial students"
        
        # Wait for all containers to be ready
        containers_ready = 0
        container_states_before = {}
        for student in initial_data:
            container_name = f'kali-jump-{student["student_id"]}'
            if self.wait_for_container_ready(container_name, max_wait=20):
                containers_ready += 1
                container_states_before[student["student_id"]] = self.check_container_health(container_name)
        
        assert containers_ready >= 2, f"Only {containers_ready}/3 initial containers started"
        print(f"  âœ… Started {containers_ready} initial containers")
        
        # Step 2: Create a new CSV with only 2 students (removing extratest003)
        # Use the actual port assignments from the running containers
        running_students = self.lab_manager.read_students_csv(csv_file)
        reduced_data = [
            {
                'student_id': 'extratest001', 
                'student_name': 'Extra Test 1', 
                'port': running_students[0]['port'], 
                'subnet_id': running_students[0]['subnet_id']
            },
            {
                'student_id': 'extratest002', 
                'student_name': 'Extra Test 2', 
                'port': running_students[1]['port'], 
                'subnet_id': running_students[1]['subnet_id']
            }
            # extratest003 is intentionally REMOVED from the new CSV
        ]
        reduced_csv_file = self.create_test_csv(reduced_data)
        
        # Step 3: Run reconciliation - this should REMOVE extratest003
        print(f"  ðŸ”„ Running reconciliation to remove extratest003...")
        success = self.lab_manager.reconcile_with_csv(reduced_csv_file)
        assert success, "Reconciliation failed"
        
        # Step 4: Verify reconciliation results
        time.sleep(5)  # Give time for removal to complete
        
        # Check that extratest003 was REMOVED
        health3_after = self.check_container_health('kali-jump-extratest003')
        assert not health3_after['running'], "extratest003 should have been REMOVED by reconciliation"
        
        # Check that extratest001 and extratest002 are still running
        health1_after = self.check_container_health('kali-jump-extratest001')
        health2_after = self.check_container_health('kali-jump-extratest002')
        assert health1_after['running'], "extratest001 should still be running after reconciliation"
        assert health2_after['running'], "extratest002 should still be running after reconciliation"
        
        print(f"  âœ… Reconciliation successfully REMOVED extratest003")
        print(f"  âœ… extratest001 and extratest002 still running as expected")
        
        # Cleanup remaining containers
        self.lab_manager.spin_down_class(reduced_csv_file, parallel=False)
    
    def test_reconcile_assignment_updates(self):
        """Test reconciliation when CSV has assignment updates"""
        print("\nðŸ”„ Testing reconcile with assignment updates...")
        
        # Create CSV with incomplete assignments
        test_data = [
            {'student_id': 'assigntest001', 'student_name': 'Assign Test 1', 'port': '', 'subnet_id': ''},
            {'student_id': 'assigntest002', 'student_name': 'Assign Test 2', 'port': '2223', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Run reconciliation (should fill in missing assignments)
        success = self.lab_manager.reconcile_with_csv(csv_file)
        assert success, "Reconciliation failed"
        
        # Verify assignments were filled in
        students = self.lab_manager.read_students_csv(csv_file)
        for student in students:
            assert student['port'] >= 2222, f"Port not assigned for {student['student_id']}: {student['port']}"
            assert student['subnet_id'] is not None and int(student['subnet_id']) > 0, f"Subnet not assigned for {student['student_id']}: {student['subnet_id']}"
        
        # Verify ports are unique
        ports = [s['port'] for s in students]
        assert len(set(ports)) == len(ports), f"Duplicate ports found: {ports}"
        
        # Cleanup any containers that might have been started
        self.lab_manager.spin_down_class(csv_file, parallel=False)
    
    @pytest.mark.slow
    def test_reconcile_mixed_add_and_remove(self):
        """Test reconciliation with both ADD and REMOVE operations in one pass"""
        print("\nðŸ”„ Testing reconcile with mixed ADD and REMOVE operations...")
        
        # Step 1: Start with initial set of students
        initial_data = [
            {'student_id': 'mixedtest001', 'student_name': 'Mixed Test 1', 'port': '', 'subnet_id': ''},
            {'student_id': 'mixedtest002', 'student_name': 'Mixed Test 2', 'port': '', 'subnet_id': ''}
        ]
        initial_csv = self.create_test_csv(initial_data)
        
        # Start the initial students
        success = self.lab_manager.spin_up_class(initial_csv, parallel=False)
        assert success, "Failed to start initial students"
        
        # Wait for initial containers
        container1_ready = self.wait_for_container_ready('kali-jump-mixedtest001', max_wait=30)
        container2_ready = self.wait_for_container_ready('kali-jump-mixedtest002', max_wait=30)
        assert container1_ready and container2_ready, "Initial containers failed to start"
        
        # Step 2: Create new CSV that removes mixedtest001 and adds mixedtest003
        running_students = self.lab_manager.read_students_csv(initial_csv)
        mixed_data = [
            # Keep mixedtest002 (no change)
            {
                'student_id': 'mixedtest002', 
                'student_name': 'Mixed Test 2', 
                'port': running_students[1]['port'], 
                'subnet_id': running_students[1]['subnet_id']
            },
            # Add new student mixedtest003
            {'student_id': 'mixedtest003', 'student_name': 'Mixed Test 3', 'port': '', 'subnet_id': ''}
            # Remove mixedtest001 (not in new CSV)
        ]
        mixed_csv = self.create_test_csv(mixed_data)
        
        # Step 3: Run reconciliation (should REMOVE mixedtest001 and ADD mixedtest003)
        print("  ðŸ”„ Running mixed reconciliation...")
        success = self.lab_manager.reconcile_with_csv(mixed_csv)
        assert success, "Mixed reconciliation failed"
        
        # Step 4: Verify the results
        time.sleep(5)  # Give time for changes to complete
        
        # mixedtest001 should be REMOVED
        health1 = self.check_container_health('kali-jump-mixedtest001')
        assert not health1['running'], "mixedtest001 should have been REMOVED"
        
        # mixedtest002 should still be running (unchanged)
        health2 = self.check_container_health('kali-jump-mixedtest002')
        assert health2['running'], "mixedtest002 should still be running"
        
        # mixedtest003 should be ADDED
        container3_ready = self.wait_for_container_ready('kali-jump-mixedtest003', max_wait=30)
        assert container3_ready, "mixedtest003 should have been ADDED"
        
        health3 = self.check_container_health('kali-jump-mixedtest003')
        assert health3['running'], "mixedtest003 should be running after being added"
        
        print("  âœ… Mixed reconciliation: REMOVED mixedtest001, KEPT mixedtest002, ADDED mixedtest003")
        
        # Verify assignments were made for the new student
        final_students = self.lab_manager.read_students_csv(mixed_csv)
        assert len(final_students) == 2, "Should have 2 students after reconciliation"
        
        mixedtest003_data = next((s for s in final_students if s['student_id'] == 'mixedtest003'), None)
        assert mixedtest003_data is not None, "mixedtest003 data should exist"
        assert mixedtest003_data['port'] >= 2222, "mixedtest003 should have assigned port"
        assert mixedtest003_data['subnet_id'] is not None and int(mixedtest003_data['subnet_id']) > 0, "mixedtest003 should have assigned subnet"
        
        # Cleanup
        self.lab_manager.spin_down_class(mixed_csv, parallel=False)


@pytest.mark.integration
class TestNetworkIsolation(TestDockerIntegration):
    """Test network isolation between students"""
    
    @pytest.mark.slow
    def test_network_isolation(self):
        """Test that students are properly isolated in separate networks"""
        print("\nðŸŒ Testing network isolation between students...")
        
        # Create test CSV with two students
        test_data = [
            {'student_id': 'nettest001', 'student_name': 'Network Test 1', 'port': '', 'subnet_id': ''},
            {'student_id': 'nettest002', 'student_name': 'Network Test 2', 'port': '', 'subnet_id': ''}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Spin up both students
        success = self.lab_manager.spin_up_class(csv_file, parallel=False)
        assert success, "Failed to spin up test students"
        
        # Wait for containers to be ready
        container1_ready = self.wait_for_container_ready('kali-jump-nettest001', max_wait=30)
        container2_ready = self.wait_for_container_ready('kali-jump-nettest002', max_wait=30)
        
        if container1_ready and container2_ready:
            # Check that each student has their own internal network
            result = self.lab_manager.run_command(["docker", "network", "ls", "--format", "json"])
            networks = []
            if result.stdout.strip():
                for line in result.stdout.strip().split('\n'):
                    if line:
                        networks.append(json.loads(line))
            
            student_networks = [net for net in networks if 'cyber-lab-nettest' in net.get('Name', '')]
            # Each student should have 1 internal network, so 2 students = 2 networks minimum
            assert len(student_networks) >= 2, f"Expected at least 2 student networks (1 per student), found: {len(student_networks)}"
            
            # Check for internal networks for each student
            internal_networks = [net for net in student_networks if 'internal' in net.get('Name', '')]
            
            assert len(internal_networks) >= 2, f"Expected at least 2 Internal networks, found: {len(internal_networks)}"
            
            print(f"  Found {len(student_networks)} student networks ({len(internal_networks)} Internal)")
        else:
            pytest.skip("Containers not ready for network isolation test")
        
        # Cleanup
        self.lab_manager.spin_down_class(csv_file, parallel=False)

    @pytest.mark.slow
    def test_network_connectivity(self):
        """Test that single-network architecture works correctly"""
        print("\nðŸŒ Testing network connectivity...")
        
        # Create test CSV with one student for focused network testing
        test_data = [
            {'student_id': 'netconntest001', 'student_name': 'Network Connectivity Test', 'port': '6666', 'subnet_id': '100'}
        ]
        csv_file = self.create_test_csv(test_data)
        
        # Spin up the student
        success = self.lab_manager.spin_up_class(csv_file, parallel=False)
        assert success, "Failed to spin up test student"
        
        # Wait for containers to be ready
        containers_ready = {}
        for container_type in ["kali-jump", "file-server"]:
            container_name = f"{container_type}-netconntest001"
            containers_ready[container_type] = self.wait_for_container_ready(container_name, max_wait=45)
            assert containers_ready[container_type], f"{container_name} failed to start"
        
        print("  âœ… All containers started successfully")
        
        try:
            # Test 1: Verify network interfaces and IP addresses
            print("  ðŸ” Verifying network configuration...")
            
            # Check Kali Jump Box (should be on internal network: 10.100.42.10)
            result = self.lab_manager.run_command([
                "docker", "exec", "kali-jump-netconntest001", 
                "ip", "addr", "show"
            ])
            kali_interfaces = result.stdout
            assert "10.100.42.10" in kali_interfaces, "Kali should have internal network IP 10.100.42.10"
            print("    âœ… Kali Jump Box: On internal network (10.100.42.10)")
            
            # Check Ubuntu Target 1 (should be on internal network: 10.100.42.11)
            result = self.lab_manager.run_command([
                "docker", "exec", "file-server-netconntest001", 
                "ip", "addr", "show"
            ])
            target1_interfaces = result.stdout
            assert "10.100.42.11" in target1_interfaces, "Target1 should have internal network IP 10.100.42.11"
            print("    âœ… Ubuntu Target 1: On internal network (10.100.42.11)")
            
            # Test 2: Verify connectivity between containers
            print("  ðŸ”— Testing connectivity...")
            
            # Kali should be able to reach Ubuntu Target 1 on internal network
            result = self.lab_manager.run_command([
                "docker", "exec", "kali-jump-netconntest001", 
                "ping", "-c", "2", "-W", "3", "10.100.42.11"
            ])
            assert result.returncode == 0, "Kali should be able to ping Ubuntu Target 1"
            print("    âœ… Kali â†’ Ubuntu Target 1: Connected")
            
            # Target 1 should be able to reach Kali on internal network
            result = self.lab_manager.run_command([
                "docker", "exec", "file-server-netconntest001", 
                "ping", "-c", "2", "-W", "3", "10.100.42.10"
            ])
            assert result.returncode == 0, "Target1 should be able to ping Kali"
            print("    âœ… Ubuntu Target 1 â†’ Kali: Connected")
            
            # Test 3: Verify routing tables
            print("  ðŸ—ºï¸  Verifying routing tables...")
            
            # Check Kali routing - should know about internal network
            result = self.lab_manager.run_command([
                "docker", "exec", "kali-jump-netconntest001", 
                "ip", "route", "show"
            ])
            kali_routes = result.stdout
            assert "10.100.42.0/24" in kali_routes, "Kali should have route to internal network"
            print("    âœ… Kali routing: Internal network accessible")
            
            # Check Target1 routing - should know about internal network
            result = self.lab_manager.run_command([
                "docker", "exec", "file-server-netconntest001", 
                "ip", "route", "show"
            ])
            target1_routes = result.stdout
            assert "10.100.42.0/24" in target1_routes, "Target1 should have route to internal network"
            print("    âœ… Ubuntu Target 1 routing: Internal network accessible")
            
            # Test 4: Test network discovery simulation
            print("  ðŸ•µï¸  Testing network discovery simulation...")
            
            # From Kali: Discover internal network
            try:
                result = self.lab_manager.run_command([
                    "docker", "exec", "kali-jump-netconntest001", 
                    "bash", "-c", "for i in {10..15}; do ping -c 1 -W 1 10.100.42.$i > /dev/null 2>&1 && echo 'Host 10.100.42.'$i' is up'; done"
                ])
            except subprocess.CalledProcessError as e:
                # Network discovery commands may return non-zero exit codes when some hosts are unreachable
                # The important thing is that we get the expected output
                result = e
                result.stdout = e.stdout
            assert "Host 10.100.42.11 is up" in result.stdout, "Should discover Ubuntu Target 1"
            print("    âœ… Internal network discovery: Ubuntu Target 1 discoverable from Kali")
            
            print("  ðŸŽ‰ All network connectivity tests passed!")
            print("     âœ… Network connectivity working correctly")
            
        except Exception as e:
            print(f"  âŒ Network connectivity test failed: {e}")
            # Print debug information
            print("  ðŸ› Debug information:")
            for container_type in ["kali-jump", "ubuntu-target1"]:
                container_name = f"{container_type}-netconntest001"
                try:
                    result = self.lab_manager.run_command([
                        "docker", "exec", container_name, "ip", "addr", "show"
                    ])
                    print(f"    {container_name} interfaces:")
                    print(f"      {result.stdout}")
                except Exception as debug_e:
                    print(f"    Failed to get debug info for {container_name}: {debug_e}")
            raise
        
        finally:
            # Cleanup
            self.lab_manager.spin_down_class(csv_file, parallel=False)


class TestStudentExec(TestDockerIntegration):
    """Test exec functionality for student containers"""

    def test_exec_into_kali_container(self):
        """Test executing actual commands in Kali container"""
        print("\nðŸ”„ Testing exec into Kali container...")
        
        # Create test student with different port to avoid conflicts
        student_data = [{
            'student_id': 'exectest001', 
            'student_name': 'Exec Test 1',
            'port': '3333',  # Use a different port to avoid conflicts
            'subnet_id': '200'  # Use a different subnet
        }]
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            csv_file = f.name
            writer = csv.DictWriter(f, fieldnames=['student_id', 'student_name', 'port', 'subnet_id'])
            writer.writeheader()
            for student in student_data:
                writer.writerow(student)
        
        try:
            # Start the student containers
            success = self.lab_manager.spin_up_class(csv_file, parallel=False)
            assert success, "Failed to start student containers"
            
            # Wait for containers to be ready
            container_ready = self.wait_for_container_ready('kali-jump-exectest001', max_wait=30)
            assert container_ready, "Kali container failed to start"
            
            # Verify container name resolution
            containers = self.lab_manager.list_student_containers('exectest001')
            assert len(containers) > 0, "No containers found for student"
            
            # Verify the expected container names exist
            container_names = [c.get('Names', '') for c in containers]
            kali_container = None
            ubuntu1_container = None
            ubuntu2_container = None
            
            for name in container_names:
                if 'kali-jump-exectest001' in name:
                    kali_container = name
                elif 'file-server-exectest001' in name:
                    ubuntu1_container = name
                elif 'build-server-exectest001' in name:
                    ubuntu2_container = name
            
            assert kali_container, f"Kali container not found. Available: {container_names}"
            assert ubuntu1_container, f"Ubuntu1 container not found. Available: {container_names}"
            assert ubuntu2_container, f"Ubuntu2 container not found. Available: {container_names}"
            
            print(f"  âœ… Found Kali container: {kali_container}")
            print(f"  âœ… Found Ubuntu1 container: {ubuntu1_container}")
            print(f"  âœ… Found Ubuntu2 container: {ubuntu2_container}")
            
            # Test that the container names follow the expected pattern
            # {service}-{student_id}
            assert kali_container == 'kali-jump-exectest001'
            assert ubuntu1_container == 'file-server-exectest001'
            assert ubuntu2_container == 'build-server-exectest001'
            
            print("  âœ… Container naming follows expected pattern")
            
            # Test actual command execution in each container type
            print("  ðŸ§ª Testing actual command execution...")
            
            # Test Kali container - check if it has Kali-specific tools
            try:
                result = self.lab_manager.run_command([
                    "docker", "exec", "kali-jump-exectest001", 
                    "bash", "-c", "whoami && echo 'KALI_TEST_SUCCESS' && which nmap"
                ])
                assert "KALI_TEST_SUCCESS" in result.stdout, "Kali container command execution failed"
                print("  âœ… Kali container exec test passed")
            except Exception as e:
                print(f"  âš ï¸  Kali container exec test failed: {e}")
            
            # Test Ubuntu1 container - check basic functionality
            try:
                result = self.lab_manager.run_command([
                    "docker", "exec", "file-server-exectest001", 
                    "bash", "-c", "whoami && echo 'UBUNTU1_TEST_SUCCESS' && ls /"
                ])
                assert "UBUNTU1_TEST_SUCCESS" in result.stdout, "Ubuntu1 container command execution failed"
                print("  âœ… Ubuntu1 container exec test passed")
            except Exception as e:
                print(f"  âš ï¸  Ubuntu1 container exec test failed: {e}")

            # Test Ubuntu2 container - check basic functionality
            try:
                result = self.lab_manager.run_command([
                    "docker", "exec", "build-server-exectest001", 
                    "bash", "-c", "whoami && echo 'UBUNTU2_TEST_SUCCESS' && ls /"
                ])
                assert "UBUNTU2_TEST_SUCCESS" in result.stdout, "Ubuntu2 container command execution failed"
                print("  âœ… Ubuntu2 container exec test passed")
            except Exception as e:
                print(f"  âš ï¸  Ubuntu2 container exec test failed: {e}")
            
        finally:
            # Cleanup
            self.lab_manager.spin_down_class(csv_file, parallel=False)
            os.unlink(csv_file)

    def test_exec_command_validation(self):
        """Test exec command validation for invalid container types"""
        print("\nðŸ”„ Testing exec command validation...")
        
        # Test invalid container type (this doesn't require actual containers)
        # We'll capture the output by temporarily redirecting stdout
        import io
        import sys
        
        old_stdout = sys.stdout
        captured_output = io.StringIO()
        sys.stdout = captured_output
        
        try:
            # This should print an error message and return
            self.lab_manager.exec_into_container('test001', 'invalid')
            output = captured_output.getvalue()
            
            assert "âŒ Invalid container type: invalid" in output
            assert "Valid types: kali, ubuntu1, ubuntu2" in output
            print("  âœ… Invalid container type properly rejected")
            
        finally:
            sys.stdout = old_stdout

    def test_exec_container_mapping(self):
        """Test that container type mapping works correctly with actual exec calls"""
        print("\nðŸ”„ Testing container type mapping...")
        
        # Create test student with different port and subnet to avoid conflicts
        student_data = [{
            'student_id': 'maptest001', 
            'student_name': 'Map Test 1',
            'port': '4444',  # Use a different port to avoid conflicts  
            'subnet_id': '201'  # Use a different subnet
        }]
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            csv_file = f.name
            writer = csv.DictWriter(f, fieldnames=['student_id', 'student_name', 'port', 'subnet_id'])
            writer.writeheader()
            for student in student_data:
                writer.writerow(student)
        
        try:
            # Start the student containers
            success = self.lab_manager.spin_up_class(csv_file, parallel=False)
            assert success, "Failed to start student containers"
            
            # Wait for containers to be ready
            container_mapping = {"kali-jump": "kali-jump", "ubuntu-target1": "file-server"}
            for container_type in ["kali-jump", "ubuntu-target1"]:
                container_name = f"{container_mapping[container_type]}-maptest001"
                container_ready = self.wait_for_container_ready(container_name, max_wait=20)
                assert container_ready, f"{container_name} failed to start"
            
            # Verify that the service mapping produces correct container names and test execution
            service_map = {
                "kali": "kali-jump",
                "ubuntu1": "file-server",
                "ubuntu2": "build-server"
            }
            
            for container_type, service_name in service_map.items():
                expected_name = f"{service_name}-maptest001"
                
                # Check if this container actually exists
                containers = self.lab_manager.list_student_containers('maptest001')
                container_names = [c.get('Names', '') for c in containers]
                
                assert expected_name in container_names, f"Expected container {expected_name} not found in {container_names}"
                print(f"  âœ… Container type '{container_type}' maps to '{expected_name}'")
                
                # Test actual command execution to verify the container is functional
                try:
                    test_command = f"echo 'EXEC_TEST_{container_type.upper()}_SUCCESS'"
                    result = self.lab_manager.run_command([
                        "docker", "exec", expected_name, "bash", "-c", test_command
                    ])
                    expected_output = f"EXEC_TEST_{container_type.upper()}_SUCCESS"
                    assert expected_output in result.stdout, f"Command execution failed in {expected_name}"
                    print(f"    âœ… Command execution successful in {expected_name}")
                except Exception as e:
                    print(f"    âš ï¸  Command execution failed in {expected_name}: {e}")
                    # Don't fail the test, just warn, as the main goal is to test container mapping
            
        finally:
            # Cleanup
            self.lab_manager.spin_down_class(csv_file, parallel=False)
            os.unlink(csv_file)

    def test_lab_manager_exec_functionality(self):
        """Test the lab manager's exec_into_container method with actual commands"""
        print("\nðŸ”„ Testing lab manager exec functionality...")
        
        # Create test student with different port and subnet to avoid conflicts
        student_data = [{
            'student_id': 'functest001', 
            'student_name': 'Function Test 1',
            'port': '5555',  # Use a different port to avoid conflicts  
            'subnet_id': '202'  # Use a different subnet
        }]
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            csv_file = f.name
            writer = csv.DictWriter(f, fieldnames=['student_id', 'student_name', 'port', 'subnet_id'])
            writer.writeheader()
            for student in student_data:
                writer.writerow(student)
        
        try:
            # Start the student containers
            success = self.lab_manager.spin_up_class(csv_file, parallel=False)
            assert success, "Failed to start student containers"
            
            # Wait for containers to be ready
            container_mapping = {"kali-jump": "kali-jump", "ubuntu-target1": "file-server"}
            for container_type in ["kali-jump", "ubuntu-target1"]:
                container_name = f"{container_mapping[container_type]}-functest001"
                container_ready = self.wait_for_container_ready(container_name, max_wait=20)
                assert container_ready, f"{container_name} failed to start"
            
            print("  ðŸ§ª Testing exec functionality for each container type...")
            
            # Get containers list once for reuse
            containers = self.lab_manager.list_student_containers('functest001')
            assert len(containers) >= 2, "Expected at least 2 containers for student"
            
            # Test exec into kali container
            print("    Testing Kali container exec...")
            try:
                # Since we can't test interactive exec in automated tests, 
                # we'll test the container name resolution and basic functionality
                
                # Find kali container and test direct exec
                kali_container = None
                for container in containers:
                    if 'kali-jump-functest001' in container.get('Names', ''):
                        kali_container = container.get('Names', '')
                        break
                
                assert kali_container, "Kali container not found"
                
                # Test the underlying functionality that exec_into_container uses
                result = self.lab_manager.run_command([
                    "docker", "exec", kali_container,
                    "bash", "-c", "echo 'Kali exec test success' && whoami"
                ])
                assert "Kali exec test success" in result.stdout, "Kali exec test failed"
                print("      âœ… Kali container exec functionality verified")
                
            except Exception as e:
                print(f"      âš ï¸  Kali container exec test failed: {e}")
            
            # Test exec into ubuntu1 container  
            print("    Testing Ubuntu1 container exec...")
            try:
                ubuntu1_container = None
                for container in containers:
                    if 'file-server-functest001' in container.get('Names', ''):
                        ubuntu1_container = container.get('Names', '')
                        break
                
                assert ubuntu1_container, "Ubuntu1 container not found"
                
                result = self.lab_manager.run_command([
                    "docker", "exec", ubuntu1_container,
                    "bash", "-c", "echo 'Ubuntu1 exec test success' && id"
                ])
                assert "Ubuntu1 exec test success" in result.stdout, "Ubuntu1 exec test failed"
                print("      âœ… Ubuntu1 container exec functionality verified")
                
            except Exception as e:
                print(f"      âš ï¸  Ubuntu1 container exec test failed: {e}")
            
            # Test the container name resolution that exec_into_container uses
            print("    Testing container name resolution...")
            service_mapping = {
                'kali': 'kali-jump-functest001',
                'ubuntu1': 'file-server-functest001',
                'ubuntu2': 'build-server-functest001'
            }
            
            for container_type, expected_name in service_mapping.items():
                # Verify the name resolution logic matches what exec_into_container expects
                actual_containers = self.lab_manager.list_student_containers('functest001')
                found_container = None
                for container in actual_containers:
                    if expected_name in container.get('Names', ''):
                        found_container = container
                        break
                
                assert found_container, f"Container {expected_name} not found for type {container_type}"
                print(f"      âœ… Container type '{container_type}' resolves to '{expected_name}'")
            
            print("  âœ… All exec functionality tests passed!")
            
        finally:
            # Cleanup
            self.lab_manager.spin_down_class(csv_file, parallel=False)
            os.unlink(csv_file)


class TestResourceLimits(TestDockerIntegration):
    """Test resource limits and security controls"""
    
    @pytest.mark.slow
    def test_fork_bomb_protection(self):
        """Test that fork bomb protection (PID limits) is working"""
        print("\nðŸ’£ Testing fork bomb protection...")
        
        # Create test CSV with one student
        test_data = [
            {'student_id': 'forkbombtest001', 'student_name': 'Fork Bomb Test', 'port': '7777', 'subnet_id': '150'}
        ]
        csv_file = self.create_test_csv(test_data)
        
        try:
            # Spin up the student
            print("  ðŸš€ Starting test containers...")
            success = self.lab_manager.spin_up_class(csv_file, parallel=False)
            assert success, "Failed to spin up test student"
            
            # Wait for containers to be ready
            containers_ready = {}
            container_mapping = {"kali-jump": "kali-jump", "ubuntu-target1": "file-server"}
            for container_type in ["kali-jump", "ubuntu-target1"]:
                container_name = f"{container_mapping[container_type]}-forkbombtest001"
                containers_ready[container_type] = self.wait_for_container_ready(container_name, max_wait=45)
                assert containers_ready[container_type], f"{container_name} failed to start"
            
            print("  âœ… Containers started successfully")
            
            # Test fork bomb protection in each container
            containers_to_test = [
                ("kali-jump-forkbombtest001", "Kali Jump Box"),
                ("file-server-forkbombtest001", "Ubuntu Target 1")
            ]
            
            for container_name, container_label in containers_to_test:
                print(f"\n  ðŸ§ª Testing fork bomb protection in {container_label}...")
                
                fork_bomb_killed_container = False
                initial_pids = None
                
                try:
                    # First, check current PID count before the test
                    result = self.lab_manager.run_command([
                        "docker", "exec", container_name,
                        "bash", "-c", "ps aux | wc -l"
                    ])
                    initial_pids = int(result.stdout.strip())
                    print(f"    Initial PID count: {initial_pids}")
                    
                except subprocess.CalledProcessError:
                    print(f"    âš ï¸  Could not get initial PID count, container may already be having issues")
                    initial_pids = 0
                
                # Attempt a fork bomb - this may kill the container (which is OK!)
                print(f"    Attempting fork bomb (this should fail due to PID limits)...")
                
                try:
                    fork_bomb_result = self.lab_manager.run_command([
                        "docker", "exec", container_name,
                        "bash", "-c", 
                        # Use timeout and try to spawn many background processes
                        "timeout 5 bash -c 'for i in {1..200}; do (sleep 10 &); done' 2>&1 || echo 'FORK_BOMB_BLOCKED'"
                    ])
                    
                    # If we get here, the command completed (didn't kill container)
                    output = fork_bomb_result.stdout + fork_bomb_result.stderr
                    print(f"    Fork bomb output: {output[:200]}...")
                    
                    # Check if we hit resource limits (expected behavior)
                    resource_limit_hit = (
                        "fork" in output.lower() or 
                        "resource" in output.lower() or
                        "FORK_BOMB_BLOCKED" in output or
                        fork_bomb_result.returncode != 0
                    )
                    
                    if resource_limit_hit:
                        print(f"    âœ… Resource limits prevented fork bomb (command failed as expected)")
                    
                except subprocess.CalledProcessError as e:
                    # Exit code 137 = SIGKILL (128 + 9) - container was killed, which is OK!
                    # This means the limits worked "too well" and killed the init process
                    if e.returncode == 137:
                        print(f"    âœ… Fork bomb killed container (exit 137 - SIGKILL)")
                        print(f"    This is ACCEPTABLE - it means PID limits protected the host by killing the container")
                        fork_bomb_killed_container = True
                    else:
                        print(f"    â„¹ï¸  Command failed with exit code {e.returncode}: {e}")
                        print(f"    This indicates resource limits are working!")
                
                # Only check container health if it wasn't killed
                if not fork_bomb_killed_container:
                    # Wait a moment for things to settle
                    time.sleep(2)
                    
                    try:
                        # Check PID count after attempt
                        result = self.lab_manager.run_command([
                            "docker", "exec", container_name,
                            "bash", "-c", "ps aux | wc -l"
                        ])
                        final_pids = int(result.stdout.strip())
                        print(f"    Final PID count: {final_pids}")
                        
                        # Verify the container is still responsive
                        health_check = self.lab_manager.run_command([
                            "docker", "exec", container_name,
                            "bash", "-c", "echo 'CONTAINER_STILL_ALIVE'"
                        ])
                        
                        container_alive = "CONTAINER_STILL_ALIVE" in health_check.stdout
                        assert container_alive, f"{container_label} became unresponsive after fork bomb attempt!"
                        
                        # Check that PID count is reasonable (not exponentially growing)
                        # With a 128 PID limit, we should never see more than ~128 processes
                        assert final_pids < 150, f"PID count too high ({final_pids}), limit may not be working!"
                        
                        print(f"    âœ… {container_label}: Fork bomb was contained!")
                        print(f"    âœ… Container remained responsive")
                        print(f"    âœ… PID count stayed under control ({final_pids} PIDs)")
                        
                    except subprocess.CalledProcessError as e:
                        # Exit 127 or namespace errors mean container died after the fork bomb
                        if e.returncode == 127 or "nsexec" in str(e):
                            print(f"    âœ… Container died after fork bomb (PID limits worked)")
                            print(f"    This is ACCEPTABLE - limits protected the host by killing the container")
                            fork_bomb_killed_container = True
                        else:
                            print(f"    âŒ Unexpected error checking container health: {e}")
                            raise
                else:
                    print(f"    âœ… {container_label}: PID limits successfully prevented fork bomb by killing container")
            
            print("\n  ðŸŽ‰ All fork bomb protection tests passed!")
            print("     âœ… PID limits are working correctly")
            print("     âœ… Containers remained stable under fork bomb attempts")
            print("     âœ… Fork bombs were successfully contained")
            
        except Exception as e:
            print(f"\n  âŒ Fork bomb protection test failed: {e}")
            raise
            
        finally:
            # Cleanup
            print("  ðŸ§¹ Cleaning up test containers...")
            self.lab_manager.spin_down_class(csv_file, parallel=False)


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s", "--tb=short"])
